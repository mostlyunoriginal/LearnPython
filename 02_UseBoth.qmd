---
title: "Recreate Some dplyr Shiz with Python and Polars"
format: html
---

```{r}
#| echo: false
#| output: false

#library(tidyverse)
```


## 1. Basic Summarize without Generalization
### r version
```{r}
library(dplyr)

table<-mtcars %>%
    group_by(cyl) %>%
    summarize(mpg.mean=mean(mpg))

print(table)

```

### python version
I'm using polars instead of pandas as it feels more natural to me coming from tidy-style R programming. I'm invoking the lazy API (instead of the eager API) by using a lazy data frame. This is actually more similar to dtplyr than dplyr. The query is assembled as `q` and then executed/compiled and saved to `table`.

While there is no pipe, the method chaining approach used below *feels* very familiar.
```{python}
import polars as pl

mtcars=pl.DataFrame(r.mtcars).lazy()

q=(
    mtcars
    .group_by(pl.col("cyl"))
    .agg(pl.col("mpg").mean().alias("mpg.mean"))
)

table=q.collect()

print(table)

```

## 2. Basic Mutate with Grouping and without Generalization
### r version
In R I can create a recode via `mutate()` that utilizes both group-level statistics and record-level data. This can be done in a single step with very little code.
```{r}
table<-mtcars %>%
    group_by(cyl) %>%
    mutate(rel.mpg=mpg/mean(mpg))

print(table)

```

### python version
With polars, it doesn't appear that I can mix the `group_by` and `with_columns` contexts. Equivalent output necessitates a 2-step approach that calculates and joins on the the group-level statistics before invoking my recode expression in the `with_columns` context, which is roughly analogous to `dplyr::mutate()`.

Note that I won't be surprised to learn that what I did above in the dplyr version *is* possible with polars and I just don't yet know how. In any case, the 2-step works and still fits within a single method chain without too much additional typing.
```{python}
q=(
    mtcars.join(
        mtcars
        .group_by("cyl")
        .agg(pl.col("mpg").mean().alias("den"))
        ,on="cyl"
        ,how="left"
    )
    .with_columns((pl.col("mpg")/pl.col("den")).alias("rel.mpg"))
    .drop("den")
)

table=q.collect()

print(table)

```

## 3. Summarize Generalized by Variable Type with Across()
### r version
```{r}
mtcars %>%
    group_by(cyl,gear) %>%
    summarize(
        across(
            .cols=where(is.double)
            ,.fns=mean
            ,.names="{.col}_mean"
        )
    )

```

### python version
Note that there are *many* selector functions available, as explained [here](https://docs.pola.rs/api/python/stable/reference/selectors.html). This is a good example of how a selector function (`cs.float()` in this case) works in conjunction with namaing methods, like `expr.name.suffix()` below. See other methods [here](https://docs.pola.rs/api/python/stable/reference/expressions/name.html).
```{python}
import polars.selectors as cs

q=(
    mtcars
    .group_by("cyl","gear")
    .agg(cs.float().mean().name.suffix("_mean"))
)

table=q.collect()

print(table)

```

## 4. Function for n & pct by Grouping Variables
In both cases I want a custom function to create simple, list-style frequency tables based on one or more variables provided by the user.
### r version
I use dynamic dots here to tunnel in the variables provided by the user in the function call. This is powerful and flexible, allowing for 0+ variables provided as naked symbols rather than strings.
```{r}
library(rlang)

doit<-function(df,...){
  df %>%
    ungroup() %>%
    mutate(N=n()) %>%
    group_by(...) %>%
    summarize(n=n(),pct=n()*100/mean(N),.groups="drop") %>%
    mutate(cumn=cumsum(n),cumpct=cumsum(pct))
}

doit(mtcars)
doit(mtcars,cyl)
doit(mtcars,cyl,gear)

```

### python version
The version below gets very close! The only differences are that the python version of `doit()` doesn't work as-is if 0 variables are provided (though it could be modifed to only conditionally invoke the `group_by` context) and the variable names are passed as strings. This latter point should actually simplify some situations that are complex due to data mask ambiguities.
```{python}
def doit(df,*argv):
    q=(
        df
        .with_columns(pl.len().alias("N"))
        .group_by(*argv)
        .agg(
            pl.len().alias("n")
            ,((pl.len()*100)/pl.col("N").mean()).alias("pct")
        )
        .sort(*argv)
        .with_columns(
            pl.col("n").cum_sum().alias("cumn")
            ,pl.col("pct").cum_sum().alias("cumpct")
        )
    )
    table=q.collect()
    print(table)

doit(mtcars,"cyl")
doit(mtcars,"cyl","gear")

```

## 5. Iterate a Custom Function
Here I want to apply the `doit` functions over parameters.
### r version
I use `purrr::pmap()` in the R version with a list of parameters. Since I defined the R version of `doit` to take naked symbols, the mapped version is kind of clunky--it would have been better had I parmaterized to take variable names as strings.
```{r}
parms<-list(
    list(mtcars,mtcars)
    ,"var1"=list(mtcars$cyl,mtcars$cyl)
    ,"var2"=list(mtcars$gear,mtcars$am)
)

purrr::pmap(parms,doit)

```

### python version
Super simple! I combine 3 parameter series into a single iterator object via `zip`--can then map `doit` over `parms` via `itertools.starmap`. Awesome!
```{python}
import itertools as it

parms=zip(
    [mtcars,mtcars]
    ,['cyl','cyl']
    ,['gear','am']
)

list(it.starmap(doit,parms))

```